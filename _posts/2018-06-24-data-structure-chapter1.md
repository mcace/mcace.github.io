---
layout: post
title:  数据结构1-绪论
date:   2018-06-24 22:19:30 +0800
categories: 数据结构
tags: [数据结构]
---

从今天起更新一套数据结构学习笔记。

这套笔记更偏向于进行一些知识点的总结归纳，因此很多细节都会被忽略掉，请勿拿本文作为入门学习，望活用搜索引擎。

本篇绪论，内容基本上都是概念性的东西，目的是在学习确切的数据结构前，先了解一些基础概念。

## 导论

数据结构在代码实践中是很重要的一部分，我们经常说一个程序等于算法加数据结构，也就描述了数据结构的重要性。

在讲数据结构之前，我们先认识一下什么是数据。

## 数据是什么

先抛定义：数据是描述客观事物的符号。

在计算机中，数据是符号的集合，是计算机可以操作的对象，能输入计算机，能由计算机识别并处理。

很晦涩是吧，其实理解起来也很简单，打个比方，我看到成绩单上写着数学78分，觉得78分太低了，于是动动笔改成了98分，或者我也可以直接把78划掉，在旁边写上100，我对"78"的种种操作，包括看到并识别出数字"78"的这个过程，就是我们对于人类世界的数据进行的各种识别和处理，同理计算机世界也有计算机能理解并处理的数据，也就是本节所讲的内容。

而数据在计算机中还有几个具体的概念：  
数据项，数据元素，数据对象，数据  
这是一个层级的关系，越往右层级越高。

- 数据项：数据不可分割的最小单位。
- 数据元素：由多个数据项构成的，有一定意义的基本单位，通常计算机里也是以数据元素为基础进行处理。
- 数据对象：由多个性质相同的数据元素组成的集合。数据对象是数据的子集。

如果你有程序经验，这一段就比较好解释了：

- 数据项：基本数据类型，比如Java和C里都有的byte、int、long等等。
- 数据元素：一个类(Class)或是结构(struct)，因为他们一般是由各种基本数据类型组成的，而且整体上也代表了某一个类型的数据，比如定义一个"人"类:
  ```java
  public class Human{
    char[] name;
    short age;
    long birthday;
    double height;
    float weight;
  }
  ```
- 数据对象：这个就简单了，一个`Human`数组，就属于一个数据对象，要记住它是一个数据元素的集合，计算机真正要处理的还是数据元素，但在那之前，计算机要先从数据对象里取出数据元素才行。

看完这些，你可能还不清楚数据到底是什么，没关系，从大的层面上看，我们粗略地认为数据对象就是计算机世界中的数据是没问题的。

## 数据结构要学什么？

数据结构是一个偏向于在实际问题中进行研究的课程，在解决实际问题时，我们要分析问题中的数据，得出数据元素之间的逻辑关系，然后根据具体的问题算法，选择与之相匹配的数据存储结构，进而得出整个数据结构，整个过程如下：

问题——>画出逻辑关系——>定义物理存储结构——>实现操作

整理一下这个过程，可以得出：

数据结构=数据的逻辑关系+数据的物理存储结构

其中逻辑关系表现了数据间的关系，物理存储结构则决定了数据结构可以实现的操作。

因此我们学习数据结构，主要学习三部分：数据的逻辑关系、数据的存储结构及相关的操作。至于数据的分析也很重要，但不是我们的侧重点。

#### 数据间的关系

其中，数据的逻辑关系可以概括为四类：

1. 集合：数据之间没有任何关系，他们仅仅被放在了一个范围内，比如说同一个猪圈里的猪。
2. 线型：数据之间是1:1的关系，比如说先后顺序，一月、二月...十二月就是一个典型的线型关系。
![](http://mcace.me/assets/images/2018/data-structure/chapter1/img1.jpg)
3. 树型：数据之间有层级，并且高层的数据可以对应多个下层数据，比如一个公司的人员组织结构就是典型的树形关系。  
![](http://mcace.me/assets/images/2018/data-structure/chapter1/img2.jpg)
4. 图型：数据之间是多对多的关系，比如地图上某个区域的多个建筑，每个建筑都可以连通多个其他建筑，他们之间的道路连通就是多对多的关系，这就是典型的图型关系。  
![](http://mcace.me/assets/images/2018/data-structure/chapter1/img3.jpg)

而物理存储结构，则是数据保存在内存中的形式。

关于数据保存在内存中我简单的形容一下：我们的程序运行在计算机上，其中大部分运行时需要的数据是保存在内存中的，内存可以看成是一个单列的文件柜，文件柜的每个抽屉里存储的就是数据，而存储的位置之间是有先后关系的，类似于下图。

![](http://mcace.me/assets/images/2018/data-structure/chapter1/img4.jpg)  

并且每个存储位置都是有它唯一的物理地址的，现阶段我们可以单纯地将物理地址看作是从下往上，从1开始逐渐变大，也就是图中绿色的数字。

物理存储结构也可以概括为四类，这里我们拿数据量为3时来举例：

1. 顺序存储结构：存储的数据按照一定顺序在对应位置存储的，并且在物理结构上是互相挨着的，比如文件柜图中的1-3、2-4、5-6区域按顺序存储所有数据。
2. 链式存储结构：存储的数据在物理结构上没有固定的位置，但也会有顺序，每个数据节点都会保存下个数据节点的地址，因此才能实现物理结构上的随意存放，举个例子：位置2存放数据节点1，同时数据节点1内存放了数据节点2的物理位置4，而数据节点2则存放了数据节点3的物理位置1。如下图：  
![](http://mcace.me/assets/images/2018/data-structure/chapter1/img5.jpg)  
   这样就形成了一个像链条一样互相串联的数据结构：  
![](http://mcace.me/assets/images/2018/data-structure/chapter1/img6.jpg)  
3. 散列
4. 索引

数据结构中，最主要的存储结构是顺序存储和链式存储，而另外两种存储方式，也会在后续再详细介绍一下。

而针对存储结构的具体操作，我们可以认为主要的操作为插入、删除、查询、修改，也就是在JAVA WEB中常有的增删改查(crud)操作。但不同的存储结构，决定了对其进行操作时的效率不同，举例来说，一个顺序存储结构，删除其中一个数据节点，那么它后面的所有数据节点就要往前移动一位，来填补删除后出现的空白，而链式存储结构删除数据节点，则只需要将该节点的前后节点相连，就可以达到无法再访问该节点的目的，删除这个操作对于这两种存储结构来说，效率是完全不一样的，顺序存储结构的删除时间复杂度为O(N),而链式则为O(1)。

#### 大O记法

__在考察算法时间复杂度时，通常使用O(x)来进行表达__，举例来说，一个有n个元素的数组从头遍历到尾，则时间复杂度为O(n)，而取第x个元素，对于顺序存储结构则是直接拿到头节点的地址加上偏移量x就可以取到指定元素，那么这样的时间复杂度为O(1)，但对于链式存储结构，由于没有办法直接确定第x个元素的地址，因此需要从头开始向后遍历到第x个元素，所以时间复杂度为O(n)。

__什么是时间复杂度？__ 一个程序执行是需要花费时间的，程序执行花费的时间和两个参数有关：算法及数据量，所以考察算法的时间复杂度，是考察随着数据量变化，程序执行时间的变化。我们也可以粗略地认为时间复杂度是考量一个算法效率的标准。

__大O记法表示的是程序执行耗费的时间随着数据量变化的变化趋势__，比如一个O(1)时间复杂度的程序，无论数据量怎么变，程序执行时间都是一个常数，而O(n)则是随着数据量变大，程序执行时间呈线性增长趋势。你可以想象一个二维坐标系，x轴表示数据量，y轴表示时间复杂度，表示执行时间与数据量关系的函数为y=ax，其中a为常数，因此这个函数描绘出来是一条直线。除此之外还有O(logn)、O(n^2)，都可以看作是y=alogn，y=an^2所描绘的图形，也就是对数级增长和指数级增长。

#### 阶段整理

下面是上述文字的阶段整理导图

![](http://mcace.me/assets/images/2018/data-structure/chapter1/img7.jpg)  

## 算法

脱离开实际的算法来讲数据结构，是不太现实的，我们知道数据结构是服务于算法的，因此在研究具体的数据结构之前，我们应当了解一些算法的基础知识。

#### 算法是什么

通俗地讲，算法就是一个问题的解题步骤，比如我们解决一个一元二次方程，就要拆解成几步来进行解题，算法的内容就是这些步骤。

另外，光有宽泛的解题步骤还不够，我们还需要有具体的代码实现，注意，步骤是步骤，始终是停留在纸面上的东西，而具体使用编程语言来实现也是完成算法重要的一环。

综上，在这里抛一个算法的定义：__算法就是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令对应一个或多个操作。__

实际上，一个问题大部分情况下都是有多种解法的，而评定不同的解法之间孰优孰劣，就需要学会考察算法的效率。

这里我们着重讲一下考察算法效率：  

- 考察的内容：算法。
- 在评定算法效率的数据上，可分为时间复杂度和空间复杂度，前者对应着算法的时间效率，后者对应着算法的空间效率。
- 在考察的时间点上，可以分为实现前考察及实现后考察，大部分书籍上叫事前分析估算和事后统计，这里我用自己的语言来叙述了。
    - 实现前考察就是通过研究算法的实现，来分析估计出算法的效率
    - 而实现后考察则是通过运行不同算法的具体实现程序，统计执行效率来进行对比  
      由于实现后考察受制于机器性能等因素影响，并且这种考察方式会造成大量时间的浪费，因此考察算法效率时我们一般都是在实现前对算法进行分析估算。

#### 算法的时间复杂度

__算法的时间复杂度主要考察随着输入的增长，算法执行时间的增长率。__

假设使用n来指代输入规模。  
那么某个算法，随着n的增大，它会越来越优于或差于另一算法。  
计算算法的时间复杂度，实际上就是考察算法中执行步骤的次数，将其转化为含n的运行次数函数式，然后推导出表示时间复杂度的大O记法。

关于如何得到运行次数函数式，我提供一个自己的办法，比较粗略也不一定对，如果有大牛肯指点我一二，万分感谢！

步骤如下：  

1. 考察循环，分析循环次数用n还是logn还是一个常数来替代。
2. 循环套循环，则是一个x*y的关系，x指上层循环的次数，y指这层循环的次数。
3. 多个循环相平行，则是一个x+y的关系。
4. 循环内的代码，视情况决定时间复杂度，大部分情况下，无论是正常的指令还是方法调用都是在常数时间内完成的，因此耗时可以用一个常数1来表示，但如果方法调用里也有循环操作，就要视情况回到步骤1来考察这个方法了。

这么一看取得运行次数函数式有点迷，那我们就用两段简单的程序来举栗子吧：

```java
public class Demo{
    public static void demoFun(String[] str_list){
        for(String str : str_list){
            str = str + "_Demo_Fun";
            System.out.println(str);
        }
    }
}

```

观察这个函数，其中有一个输入数据str_list，我们将其数据量用n表示。  
其中有一个循环，循环的次数观察一下显然是n，因此我们可以暂时得出时间复杂度函数式为f(n)=n。  
接下来看循环内容，其中连接字符串的操作和println的操作都可以视为常数时间的操作，因为是在循环内，所以直接用一个1来替代常数，因此时间复杂度函数式可以认为是f(n)=1*n=n。

再举一个例子，比如说冒泡排序的时间复杂度：

```java
public class BubbleSort{
    public static void bubble(int[] arr){
        for(int i = arr.length - 1; i > 0; i--){
            for(int j = 0; j < i; j++){
                if(arr[j] > arr[j + 1]){
                    int temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                }
            }
        }
    }
}
```

我们考察这个算法，可以看到是一个嵌套双重循环的结构，且每次循环都可以认定为从0到n，并且其中的操作可以用常数时间表示，因此这个算法的运行次数函数式可以认为是f(n)=n^2。

经过上面的步骤，我们现在有了一个含n的运行次数函数式，它表达了算法执行时间和数据规模的函数关系，接下来我们要将其转化为大O记法，这个过程也可以叫推导大O阶。

推导大O阶只需要遵循下面的步骤即可：

1. 只保留函数中的n的最高阶项
2. 用常数1取代运行时间中的所有加法常数
3. 如果最高阶项存在且不是1，则去除与这个项相乘的常数

这么一说看起来有点迷，我们这里用一个函数式来举个栗子吧：

f(n)=5n^2+9n+23+4  
第一步，保留最高阶项，最高阶项是5n^2，函数式变成：  
f(n)=5n^2  
第二步，没有加法常数，略过  
第三步，存在最高阶项5n^2，去除与之相乘的常数5，函数式最后变为：  
f(n)=n^2  
结论：算法时间复杂度为O(n^2)

大家可以试试自己算一下  
f(n)=4logn+32  
f(n)=nlogn+10  
f(n)=n+96  
f(n)=8n^2+3logn+4  
f(n)=5logn+6n+2  
f(n)=10086

答案分别为O(logn)，O(nlogn)，O(n)，O(n^2)，O(logn)，O(1)。

在这里，我们可以看到时间复杂度的几个常用阶：常数、n、logn、n^2。

简单地介绍一下这几个常用阶：

- 常数：表示运行时间是固定的，不会因输入规模改变而改变
- n:线性阶，表示运行时间与输入规模呈线性增长趋势
- logn:对数阶，表示运行时间与输入规模呈对数增长趋势
- n^2:平方阶，表示运行时间与输入规模呈平方级增长趋势

现在我们已经可以用大O记法来表示一个算法的时间复杂度了，但我们还要明确这个大O记法的具体含义，也就是它指代的是程序在什么情况下的一个运行时间复杂度。

我们考察一个算法消耗的时间，一般有最坏情况和平均情况两种情况：

- 最坏情况：表示运行时间不会再差了。
- 平均情况：表示程序运行的期望时间，需要通过一定数量的实验数据运行估算后得出。

大O记法一般情况下研究的就是算法的最坏运行情况，记住这一点，抛开具体的数据，把所有情况都往差了想，一个循环就是要他从头遍历到尾，if判断就是要视为true和false各占一半或是只走一边的情况。

__最后做一下本节的总结吧：考察一个算法的时间复杂度，首先要将其转换成含n的运行次数函数式，然后推导其大O阶。大O记法表示的时间复杂度都是考虑最坏情况的__

#### 算法的空间复杂度

一个算法的运行不只会用到时间，也会用到存储空间，这里抛出对空间复杂度的定义：

__空间复杂度是一个算法在运行过程中临时占用存储空间大小的量度。__

